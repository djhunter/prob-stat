---
title: "Conditional Probability and Independence"
output: 
  revealjs::revealjs_presentation:
    fig_width: 14 
    fig_height: 7
    self_contained: true
    theme: night
    highlight: zenburn
    css: slidesdjh.css
    center: false
    transition: slide
    reveal_options:
      controls: true
      progress: false
      width: 1080
      height: 540
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(comment = NA)
options(width = 100)
```


# Overview

- Conditional probability in the discrete case
    - Independence
- Continuous conditional probability
- Joint density and cumulative distribution functions
    - Independence
    
For further reading, see [GS], pp. 162-168.

# Conditional Probability

## Conditional Probability

Let $E$ and $F$ be events in a sample space $\Omega$. 

- The **conditional probability** of $F$ given $E$ is denoted $P(F \mid E)$.
- $P(F \mid E)$ is the probability that $F$ occurs, given that $E$ has/must occur(red).

Examples (discrete):

- Flip three coins. What is the probability that all are heads, given that the first is heads?
- Roll a six-sided die. What is the probability of rolling a six, given that the roll is even?

## Rules for conditional probability

>- Restriction rule: The conditional probability of $F$ given $E$ is the probability of $F$ when we *restrict* the sample space to $E$:
$$
P(F \mid E) = \frac{P(F \cap E)}{P(E)}
$$
>- Multiplication rule: $P(F \cap E) = P(F)\cdot P(E \mid F) = P(E)\cdot P(F \mid E)$
>    - Two events are **independent** iff $P(E \cap F) = P(E)P(F)$.
>- Bayes' rule: 
$$
P(F \mid E) = \frac{P(E\mid F)\cdot P(F)}{P(E)} = \frac{P(E \mid F)\cdot P(F)}{P(F)\cdot P(E \mid F) + P(\tilde{F})\cdot P(E \mid \tilde{F})}
$$

## Group Exercise

It is estimated that 1% of the population have a certain rare disease. A test for this disease will correctly detect an infection 98% of the time. However, this test has a 5% false positive rate: That is, the probability that someone tests positive, given that they don't have the disease, is 0.05. What is the probability that a randomly chosen person has this disease, given that they tested positive for it?

---
# exercises 26, 29 on pp. 153-154 of [GS]
---

# Continuous Conditional Probability

## PDFs for conditional probability

Suppose $X$ is a continuous random variable with density function $f(x)$. Let $E$ be an event with nonzero probability. Then the **conditional density function** for $X$ given $E$ is

$$
f(x \mid E) = \begin{cases} 
f(x)/P(E) & \text{if } x \in E \\
0 & \text{if } x \not\in E
\end{cases}
$$
Sanity check: This definition is consistent with the restriction rule:

$$
P(F \mid E) = \int_F f(x \mid E) \, dx = \int_{E \cap F} \frac{f(x)}{P(E)} \, dx = \frac{P(E \cap F)}{P(E)}
$$

. . .

Example: Let $X = \text{rnd}$. What is $P(X \geq 3/4 \mid X \geq 1/4)$?

## Group Exercise

Let $X$ and $Y$ be uniform random variables on $[0,1]$, and let $Z = X + Y$. Last time we proved that $Z$ has the following PDF:
$$
f(z) = \begin{cases}
0 & \text{if } z<0 \\
z & \text{if } 0 \leq z \leq 1 \\
2-z & \text{if } 1 \leq z \leq 2 \\
0 &\text{if } z > 2
\end{cases}
$$

Let $E$ be the event that $Z$ is greater than 0.5. Derive a formula for $f(x \mid E)$, and compute the probability that $Z$ is greater than 1, given that it is greater than 0.5.

## Example: Exponential density

The [Earthquate Robot](https://twitter.com/earthquakebot) Twitter account sends out a tweet whenever there is a earthquake somewhere in the world with magnitude greater than 5.0. The number of hours $X$ between such earthquakes can be modeled by the exponential distribution.
$$
f(x) = \begin{cases}
0.2 e^{-0.2x} & \text{if } x \geq 0 \\
0 & \text{if } x < 0
\end{cases}
$$

1. What is the probability that there will be an earthquake in the next 12 hours?
2. What is the probability that there will be an earthquake between 10 and 22 hours from now, given that there won't be an earthquake in the next 10 hours?

# Joint Density Functions

## Motivating example

1. Consider drawing a point at random from the square region $[0,1] \times [0,1]$. Let $X$ and $Y$ be the coordinates of the point.
2. Consider drawing a point at random from the region bounded by the triangle with vertices $(0,0)$, $(1,0)$, and $(0,1)$. Let $X$ and $Y$ be the coordinates of the point.

In each case, does the distribution of $Y$ depend on the value of $X$ (and vice versa)?

## Independence

Two continuous random variables $X$ and $Y$ are **independent** if the conditional PDF for $X$ given $Y = y$ does not depend on $y$. That is, for any value of $y$,
$$
f_{X \mid Y}(x \mid Y = y) = f_X(x)
$$
is a function of $x$ only (and not $y$).

## Double integrals

- A (positive, continuous) function of two variables $z = f(x,y)$ defines a surface (above the $xy$-plane).
- The *volume* between a region $E$ in the $xy$-plane and the surface is given by the **double integral**
$$
\iint_E f(x,y)\, dy \, dx
$$

## Joint density functions

Suppose the sample space $\Omega$ is two-dimensional: $\Omega \subseteq \mathbb{R}^2$. In this case we can consider random variables $(X, Y)$ drawn from this sample space, and an event $E$ is a two-dimensional region in $\Omega$. A **joint density function** for $X$ and $Y$ is a function $f(x,y)$ such that
$$
P((X,Y)\in E) = \iint_E f(x,y) dy \, dx
$$

## Joint cumulative distribution functions

Similarly, we can define the **joint cumulative distribution function** for $X$ and $Y$ as
$$
F(x,y) = P(X \leq x \text{ and } Y \leq y)
$$

Facts: $f$ and $F$ are related as follows.
$$
F(x,y) = \int_{-\infty}^x \int_{-\infty}^y f(s,t) \, dt \, ds
$$
and 
$$
f(x,y) = \frac{\partial^2F(x,y)}{\partial x \partial y}
$$


## Equivalent conditions for independence

Suppose $X$ and $Y$ are continuous random variables with PDFs $f_X(x)$ and $f_Y(y)$ and CDFs $F_X(x)$ and $F_Y(y)$. Then either of the following conditions imply that $X$ and $Y$ are independent.

- The joint density function $f(x,y) = f_X(x) f_Y(y)$.
- The joint distribution function $F(x,y) = F_X(x)F_Y(y)$.

For more details, see [ER], pp. 95-100.

. . .

Example: $f(x,y) = 4xy$ on $\Omega = [0,1]\times[0,1]$

