---
title: "Discrete Probability Distributions"
output: 
  revealjs::revealjs_presentation:
    fig_width: 14 
    fig_height: 7
    self_contained: true
    theme: night
    highlight: zenburn
    css: slidesdjh.css
    center: false
    transition: slide
    reveal_options:
      controls: true
      progress: false
      width: 1080
      height: 540
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(comment = NA)
options(width = 100)
```


# Overview

- Simulation of Discrete Probabilities
    - Discrete random variables
    - Distribution functions
    - R
- Discrete Probability Distributions
    - Random Variables, Sample Spaces, Distribution Functions
    - Properties of Discrete Probability

For further reading, see [GS], pp. 1-40.

# Simulation of Discrete Probabilities

## Discrete Random Variables

A **random variable** is an expression whose value is the outcome of a random experiment.

- Example: Roll a 6-sided die. Let $X$ be the number that comes up.
    - $P(X = 1) = P(X = 2) = \cdots = P(X = 6) = 1/6$
    - $P(X \leq 4) = 2/3$
- Example: Flip 2 coins. Let $Y$ be the total number of heads.
    - $P(Y = 0) = 0.25$, $P(Y = 1) = 0.5$, $P(Y = 2) = 0.25$

## Distribution Functions

A **distribution function** $m$ assigns a nonnegative number $m(\omega_j)$ to each possible
value $\omega_j$ of a random variable.

- Example: Roll a 6-sided die. Let $X$ be the number that comes up.
    - Possible outcomes: $\omega_1 = 1, \omega_2 = 2, \ldots, \omega_6 = 6$.
    - $m(\omega_j) = 1/6$ for all $j$.
- Example: Flip 2 coins. Let $Y$ be the total number of heads.
    - Possible outcomes: $\omega_1 = 0, \omega_2 = 1, \omega_3 = 2$.
    - $m(\omega_1) = 0.25$, $m(\omega_2) = 0.5$, $m(\omega_3) = 0.25$
    
. . .

Note: A distribution function always has "total mass" 1:

$$
\sum_{\text{all } j} m(\omega_j) = 1
$$

## Example: Peter and Paul

Peter and Paul play a game: flip a coin 40 times. 

- If heads, Peter wins one dollar from Paul. 
- If tails, Peter gives one dollar to Paul.
- Let $X$ be Peter's total winnings. How is $X$ distributed?

(See R Console for a demonstration)

## Simulation using R (summary)

```{r, fig.align='center', fig.width=6, fig.height=3.5}
set.seed(1234)
pwinnings <- replicate(10000, sum(sample(c(-1,1), 40, replace = TRUE)))
probs <- table(pwinnings)/10000
plot(probs)
```

## Example: Roll until you get a 6

- You get one dollar for each roll of a six-sided die.
- You keep rolling till you get a 6.

(See console for demo)

## Group Exercise

<div class="column-left">

1. What is the exact probability of winning 1 dollar (i.e., of rolling a 6 on the first roll)? Does this match the graph from the simulation?
2. What is the exact probability of winning 2 dollars (i.e., of rolling a non-6 on the first roll, then rolling a 6 on the second roll)?
3. What is the exact probability of winning $k$ dollars?

</div>

<div class="column-right">
```{r, fig.align='center', fig.width=4, fig.height=4, echo=FALSE}
set.seed(4321)
dwinnings <- replicate(10000, {
  i <- 1
  while(sample(6, 1) != 6) i <- i + 1
  i
  })
probs <- table(dwinnings)/10000
plot(probs)
```

</div>

## Simulation using R (distribution)

```{r, fig.align='center', fig.width=6, fig.height=3.5}
set.seed(4321)
dwinnings <- replicate(10000, {
  i <- 1
  while(sample(6, 1) != 6) i <- i + 1
  i
  })
probs <- table(dwinnings)/10000
plot(probs)
```


## Simulation using R (mean winnings)

```{r, fig.align='center', fig.width=6, fig.height=3.5}
set.seed(4321)
dwinnings <- replicate(10000, {
  i <- 1
  while(sample(6, 1) != 6) i <- i + 1
  i
  })
mean(dwinnings)
```


---
#   ## Example: Times in lead
#   
#   - Let $Y$ be the number of times during the game that Peter's winnings are positive.
#   - How is $Y$ distributed?
#   
#   (See R Console)
#   
#   ## Times in lead (summary)
#   
#   ```{r, fig.align='center', fig.width=6, fig.height=3.5}
#   set.seed(1234)
#   pinlead <- replicate(10000, sum(cumsum(sample(c(-1,1), 40, replace = TRUE)) > 0))
#   probs2 <- table(pinlead)/10000
#   plot(probs2)
#   ```
---

---
# Exercise: Random walk (1D) how is distance from zero distributed? what is the average distance from zero?
---

# Discrete Probability Distributions

## Random Variables, Sample Spaces, Distributions

- The **sample space** $\Omega$ of a random experiment is the set of all possible outcomes.
- An **event** is a subset of a sample space.
- A **random variable** is a numerical result of a random experiment.

. . . 

*Warning.* These definitions depend on which book you read.

- [GS] uses "random variable" and "sample space" interchangeably, sometimes. (See pp. 18-19) 
- [ER] defines a random variable as a function $X : \Omega \longrightarrow \mathbb{R}$. (See pp. 34-38)


## Example: Flip a coin twice.

There is more than one way to represent the sample space.

- Sample space: $\Omega = \{TT, TH, HT, HH\}$
    - Event that the coins differ: $E = \{TH, HT\}$
    - Random variable: $X =$ number of heads.
- Alternatively, Sample space $\Omega = \{0, 1, 2\}$
    - Event that the coins differ: $E = \{1 \}$
    - $X(\omega) = \omega$, for all $\omega \in \Omega$.

## Distribution Functions

A **distribution function** is a function $m$ that assigns a probability to each $\omega \in \Omega$.

- $m : \Omega \longrightarrow [0, 1]$
- $\displaystyle{\sum_{\omega \in \Omega}} m(\omega) = 1$
- If $E \subseteq \Omega$, then the **probability** of the event $E$ is $P(E) = \displaystyle{\sum_{\omega \in E}} m(\omega)$

## Group Exercise

Let $\Omega = \{a, b, c, d}$ with $m(a) = m(b) = 2m(c) = 3m(d)$. 

1. Determine $m(a), m(b), m(c), m(d)$.

2. Let $E = \{b, c\}$ be an event. Compute $P(E)$ and $P(\tilde{E})$. ($\tilde{E}$ is the set complement of $E$.)

3. Let $F = \{c, d \}$. Compute $P(E \cup F)$.

## Properties of discrete probability

See [GS], pp. 22-24.

- Theorem 1.1: Elementary properties
- Theorem 1.2, 1.3: Disjoint events
- Theorem 1.4: Inclusion-Exclusion principle

## Odds

Suppose $P(E) = p$.

- The **odds** in favor of $E$ are $r : s$ ($r$ to $s$) where $r/s = p/(1-p)$.
- If the odds of $E$ are $r$ to $s$, then $P(E) = r/(r + s)$.

. . . 

Example, a sports book is giving 15 to 1 odds that a certain team wins the Super Bowl.

- You win 15 dollars for a 1 dollar bet.
- If the probability that this team will win is $1/16$, the book will break even. (Check this.)
